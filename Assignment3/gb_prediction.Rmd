---
title: "Question 1"
output: md_document
---

```{r include=FALSE, cache= TRUE}

library(mosaic)
library(tidyverse)
library(Metrics)
library(gamlr)
library(margins)
library(rpart)
library(caret)
library(knitr)
library(randomForest)
library(gbm)
greenbuildings = read.csv("greenbuildings.csv", header=TRUE)
greenbuildings = na.omit(greenbuildings)
gb = greenbuildings[which(greenbuildings$leasing_rate != 0),]
gb$size = gb$size/1000

```

# Question 1. Predictive model for Green Buildings

Using the data on 7,984 commercial rental properties from the United States, the goal is to build a predictive model for rental income per square foot. To build the model we have several key features of each property such as size in square foot, leasing rate, number of stories, amenities, among others. We also have information about building's "neiborhood", weather in the area and kind of contract that the property offers. Beyond the amount of variables we have, we are specially interested in quantifying the average change in rental income per square foot  associated with green certification, holding other features of the building constant. In this dataset, 685 properties have been awarded either LEED or EnergyStar certification as a green building.

To adress this problem we use different approachs we have seen in class. The first approach is from the point of view of linear models, including model regularization techniques and stepwise selection. In the second approach we use a Lasso regression model and cross validation, to try to find a best model. Finally we implement tree models, random forest and boosting. 

## Approach #1 Linear models and stepwise selection 

To start we cleaned our database eliminating the properties that are without occupation and the entries with missing data. After that, we proceed creating a model that include variables we consider are relevant to explain the rent price. It is important to remark that we decided working with the variable that summarize green rating which takes value of 1 if the property has at least one green certifification and zero otherwise. Then, the first model we fitted is a linear one, called manual, that include most of the variables available, we mainly dropped variables that seemed to do not explain to much in our model. These variableswere property ID, precipitation days, cold and hot degree days, however we included total degrees days. After the first model, we regress a second one with the same varianles but now considering all the interactions between covariates. Having our two first models, the next step was working with the function step to look for a model that improves the AIC of the previous ones. To do that we created a null model and ran the function step to find a better model based on the scope of variables of the two originals models. After we got the new 2 models, we splitted up our sample in a train and test subsamples. To validate our models we generated out of sample RMSEs boostrapping our data. 

```{r include=FALSE, cache= TRUE}

#############################################################
#####APPROACH 1 fitting Linear models and step selection ############
#############################################################

#### Null model####
m0 = lm(Rent~1, data=gb)
summary(m0)

#### Manual built model####
m1  = lm(Rent ~ . -CS_PropertyID-LEED-Energystar
          -Precipitation-cd_total_07-hd_total07, data=gb)
summary(m1)

#### Manual model allowing interactions ####
m2  = lm(Rent ~ (. -CS_PropertyID-LEED-Energystar
                 -Precipitation-cd_total_07-hd_total07)^2, data=gb)
summary(m2)

#### Step selection ####
m3 = step(m0, scope=formula(m1), dir="forward")
summary(m3)
formula(m3)

m4 = step(m0, scope=formula(m2), dir="forward")
summary(m4)
formula(m4)
marm4=margins(m4)

# Compare out of sample performance
n = nrow(gb)
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
rmse_lm = do(50)*{
    # re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train, replace=FALSE)
  test_cases = setdiff(1:n, train_cases)
  gb_train = gb[train_cases,]
  gb_test = gb[test_cases,]
  
  # Fit to the training data
  # use `update` to refit the same model with a different set of data
  lm1 = update(m1, data=gb_train)
  lm2 = update(m2, data=gb_train)
  lm3 = update(m3, data=gb_train)
  lm4 = update(m4, data=gb_train)
  
  # Predictions out of sample
  yhat_test1 = predict(lm1, gb_test)
  yhat_test2 = predict(lm2, gb_test)
  yhat_test3 = predict(lm3, gb_test)
  yhat_test4 = predict(lm4, gb_test)
  
  c(rmse(gb_test$Rent, yhat_test1),
    rmse(gb_test$Rent, yhat_test2),
    rmse(gb_test$Rent, yhat_test3),
    rmse(gb_test$Rent, yhat_test4))
}

rmse.lm=colMeans(rmse_lm)
aic.lm=AIC(m1,m2,m3,m4)
bic.lm=BIC(m1,m2,m3,m4)
```

**Table 1. RSME, AIC and BIC for linear models**
```{r echo=FALSE, warning= FALSE, cache= TRUE}
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df

a=cbind(rmse.lm,AIC,BIC,DF)
colnames(a)<-c("RMSE","AIC","BIC","DF")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
                        ","Model 3: Manual built + step","Model 4: Interactions + step")
table1=kable(a, digits=2, padding = 2)
table1
```

Table 1 summarizes the information of the four linear models we built. we can see that the model with the lowest RMSE is the model 4 generated by the step function based on the all interactions model. We can also see that this model has the second lowest AIC, only improved by model 2. However, we decided to include BIC criteria too, since it penalizes the number of coefficientes included in a model. With this criteria, the model 4 is the better, considering it is a more parsimonious model than model 2. 

## Approach #2  Lasso Regression: Variable Selection and Regularization  
```{r include=FALSE, cache= TRUE}
##############################################################
####### APPROACH 2 Lasso Regression and Regularization #######
##############################################################
rmse_lasso = do(10)*{
  # re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train, replace=FALSE)
  test_cases = setdiff(1:n, train_cases)
  gb_train = gb[train_cases,]
  gb_test = gb[test_cases,]
  x_train= sparse.model.matrix(Rent ~ (.-CS_PropertyID-LEED-Energystar)^2, data=gb_train)[,-1] # do -1 to drop intercept!
  x_test= sparse.model.matrix(Rent ~ (.-CS_PropertyID-LEED-Energystar)^2, data=gb_test)[,-1]
  y=gb_train$Rent

###### CV Lasso best model ######
cvm5= cv.gamlr(x_train, y, nfold=10,  verb=TRUE)

# plot the out-of-sample deviance as a function of log lambda
# Q: what are the bars associated with each dot? 
plot(cvm5, bty="n")

## CV min deviance selection
scb.min = coef(cvm5, select="min")
lambda=log(cvm5$lambda.min)
coef.lasso=sum(scb.min!=0) 

yhat_test5 = as.numeric(predict(cvm5, x_test, select="min"))

c(rmse(gb_test$Rent,yhat_test5),lambda,coef.lasso)

}

info.lasso=colMeans(rmse_lasso)
lambda1=info.lasso[2]
coef.lasso1=info.lasso[3]

```  

The second approach is from the point of view of lasso regression. Working with the same data as the linear models, the only extraa step we needed to take before start with lasso models was the creation of sparse matrices for training and testing subsamples. The sparse matrices included the same variables of our manual linear model plus all the interactions, the last in order to have and equivalent scope of linear models. We went straight to use the cross validation function to find the best lasso model to predict rent. The cross validation function finds the lasso model tha minimized the lambda and drops all the coefficients that are close to be zero. We know when lambda is close to zero the betas found by lasso are essentially the least squares estimates. Thus, we implemented a cross validation lasso regression considering 10 folds and bostrapped again the process several times. 

**Table 2. Evaluation of Lasso Model**
```{r echo=FALSE, warning= FALSE, cache= TRUE}
info.lasso=as.data.frame(info.lasso)
colnames(info.lasso)<-c("Model 5: Lasso Model")
row.names(info.lasso) <- c("RMSE","Log Lambda",
                        "Number of coefficients")
table2=kable(info.lasso,digits=2)
table2
```

Table 2 contains the average results of the lasso cross validation. The model found has in average a log lambda of `r lambda1` and in average includes `r coef.lasso1` coefficients. However, the findings suggests that the lasso selected model does not improve the best linear model built in the previous section according with the boostrapped out of sample RSME computed. In graph 1, we show the evolution of a lasso regression for one case. We can appreciate how lasso approach found the minimum RMSE in a number of coefficients similar to the coefficients included in the best linear regression. The last reinforces that the linear model could be a good predictor of rent price.  

**Graph 1. Lasso model: Errror vs Log Lambda**
```{r echo=FALSE, warning= FALSE, cache= TRUE}
plot(cvm5, bty="n")
```


## Approach #3 Tree Models, Random Forest and Boosting 
```{r include=FALSE, cache= TRUE}

############################  
###### 3.A. Tree model #####
rmse_tree = do(50)*{
# re-split into train and test cases with the same sample sizes
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
gb_train = gb[train_cases,]
gb_test = gb[test_cases,]

m6= rpart(Rent ~ .-CS_PropertyID-LEED-Energystar, method="anova",data=gb_train,
              control=rpart.control(minsplit=5, cp=1e-6, xval=10))
nm6 = length(unique(m6$where))

# calculate the cv error + 1 standard error
# the minimum serves as our threshold
err1se = m6$cptable[,'xerror'] + m6$cptable[,'xstd']
errth = min(err1se)

# now find the largest simplest tree that beats this threshold
m6$cptable[,'xerror'] - errth
stree=min(which(m6$cptable[,'xerror'] - errth < 0)) 
bestm6 = m6$cptable[stree,'CP']

###### Cross validation tree model ####
cvm6 = prune(m6, cp=bestm6)
length.btree=length(unique(cvm6$where))
plot(cvm6)
text(cvm6)

yhat_test6 = predict(cvm6, gb_test)
c(rmse(gb_test$Rent,yhat_test6),length.btree)
}
info.trees=colMeans(rmse_tree)
####################################
##### 3.B. Random Forest Model #####
m7 = randomForest(Rent ~ .-CS_PropertyID-LEED-Energystar,
                  data = gb_train, mtry = 5, ntree=500)
plot(m7)
yhat_test7 = predict(m7, gb_test)
rmse.rf=rmse(gb_test$Rent,yhat_test7)
varImp(m7) 
varImpPlot(m7,type=2,main="Variable Importance")

####################################
##### 3.C. Boosting Model #########

m8 = gbm(Rent ~ .-CS_PropertyID-LEED-Energystar,
         data = gb_train,n.trees=5000, shrinkage=.05)
yhat_test8= predict(m8, gb_test, n.trees=5000)
summary(m8)
rmse.boost=rmse(gb_test$Rent,yhat_test8)

```  

As a final approach, we work with tree models, random forest and boosting. First we worked with a simple tree model to predict rent price. About trees we known that they are good to manipulate large dataset and to ignore redundant data, we know they are not the best model to prediction though. A full tree was grown on the training set, with splitting continuing until a minimum bucket size of 5 was reached. This tree was pruned, and the tree size was chosen by 10-fold cross-validation. we repeated this approach several times by data boostrapping to generate out of sample RMSEs. 
After the simple tree, we proceeded with a random forest. This method fit many large trees to bootstrap-resampled versions of the training data
by relevance. We created 500 trees by random forest including a minimum of 5 features per bucket, and later we compute the out of sample RMSE. Finally, we performed a boosting model, that mainly fits several trees to reweighted versions of the training dataset and then classifies by weighted majority relevance. We fitted 5000 trees by this method with a shrinkage factor of 0.05. 

**Table 3. Tree, Random Forest and Boosting comparative**
```{r echo=FALSE, warning= FALSE, cache= TRUE}
table3=as.data.frame(c(info.trees[1],rmse.rf,rmse.boost))
colnames(table3)<-c("RMSE")
row.names(table3) <- c("Model 6: Tree model","Model 7:Random Forest",
                           "Model 8: Boosting")
table3=kable(table3,digits=2) 
table3
```

Table 3 summarizes the RMSE of the last tree model fitted. We can see that when the simple tree model does not improve the previous models, the random forest model and the boosting model certainly outperfom all the models. The best model we have built to predict the rent price per square foot so far is the random forest model with the least out of sample RMSE. However, now we face the problem that random forest model are certainly not interpretable and we want to know the partial effect of being a green building over price. Despite of this limitation random forest models allow us to get a importance meaure of each variable in the model.It just adds up how much the error decreases every time a variable is used in a split. This information is contained in graph 2. we can observe that the most importan variable is the rent price in the cluster where our property is located, followed by size and so on. 

**Graph 2. Varibale importance (Random Forest)**
```{r echo=FALSE, warning= FALSE, cache= TRUE}
varImpPlot(m7,type=2,main="")
```

```{r include=FALSE, cache= TRUE}
marm4
```
## Concluding Remarks

With data on 7,984 commercial rental properties from the United States, we built eight models to predict the rent price per square foot. The approaches implemented varie from linear models, going throug step selection, lasso regression until to tree models, random forest and boosting. The out of sample results suggets that the model with the lowest error is the random forest model with a RMSE of `r rmse.rf`. We also were requested to find the the average change in rental income per square foot  associated with green certification. Given the barrier we have to get this kind of interpretation from a random forest model. We computed the average marginal effect of being a green building from the best linear model we fitted (Model 4). The results suggest that having a green certification leads an increasing in 1.307 dollars per square foot in rent price. This result makes sense since green building properties have positive features such as lower energy compsumption levels, variable that according with our random forest model is important to explain rent price. 



