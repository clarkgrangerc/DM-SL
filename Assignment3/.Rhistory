x_train= sparse.model.matrix(Rent ~ (.-CS_PropertyID-LEED-Energystar)^2, data=gb_train)[,-1] # do -1 to drop intercept!
x_test= sparse.model.matrix(Rent ~ (.-CS_PropertyID-LEED-Energystar)^2, data=gb_test)[,-1]
y=gb_train$Rent
###### CV Lasso best model ######
cvm5= cv.gamlr(x_train, y, nfold=10,  verb=TRUE)
# plot the out-of-sample deviance as a function of log lambda
# Q: what are the bars associated with each dot?
plot(cvm5, bty="n")
## CV min deviance selection
scb.min = coef(cvm5, select="min")
lambda=log(cvm5$lambda.min)
coef.lasso=sum(scb.min!=0)
yhat_test5 = as.numeric(predict(cvm5, x_test, select="min"))
c(rmse(gb_test$Rent,yhat_test5),lambda,coef.lasso)
}
info.lasso=colMeans(rmse_lasso)
info.lasso=as.data.frame(info.lasso)
colnames(info.lasso)<-c("Lasso Model")
row.names(info.lasso) <- c("RMSE","Log Lambda",
"Number of coefficients")
table2=kable(info.lasso,digits=2)%>%
kable_styling(bootstrap_options = "striped", position = "float_right")
table2
(cvm5$lambda.min)
info.lasso=as.data.frame(info.lasso)
colnames(info.lasso)<-c("Lasso Model")
row.names(info.lasso) <- c("RMSE","Log Lambda",
"Number of coefficients")
table2=kable(info.lasso,digits=2)%>%
kable_styling(bootstrap_options = "striped", position = "float_right")
table2
plot(cvm5, bty="n")
table3=as.data.frame(c(info.trees[1],rmse.rf,rmse.boost))
############################
###### 3.A. Tree model #####
rmse_tree = do(50)*{
# re-split into train and test cases with the same sample sizes
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
gb_train = gb[train_cases,]
gb_test = gb[test_cases,]
m6= rpart(Rent ~ .-CS_PropertyID-LEED-Energystar, method="anova",data=gb_train,
control=rpart.control(minsplit=5, cp=1e-6, xval=10))
nm6 = length(unique(m6$where))
# calculate the cv error + 1 standard error
# the minimum serves as our threshold
err1se = m6$cptable[,'xerror'] + m6$cptable[,'xstd']
errth = min(err1se)
# now find the largest simplest tree that beats this threshold
m6$cptable[,'xerror'] - errth
stree=min(which(m6$cptable[,'xerror'] - errth < 0))
bestm6 = m6$cptable[stree,'CP']
###### Cross validation tree model ####
cvm6 = prune(m6, cp=bestm6)
length.btree=length(unique(cvm6$where))
plot(cvm6)
text(cvm6)
yhat_test6 = predict(cvm6, gb_test)
c(rmse(gb_test$Rent,yhat_test6),length.btree)
}
info.trees=colMeans(rmse_tree)
####################################
##### 3.B. Random Forest Model #####
m7 = randomForest(Rent ~ .-CS_PropertyID-LEED-Energystar,
data = gb_train, mtry = 5, ntree=500)
plot(m7)
yhat_test7 = predict(m7, gb_test)
rmse.rf=rmse(gb_test$Rent,yhat_test7)
varImp(m7)
varImpPlot(m7,type=2,main="Variable Importance")
####################################
##### 3.C. Boosting Model #########
m8 = gbm(Rent ~ .-CS_PropertyID-LEED-Energystar,
data = gb_train,n.trees=5000, shrinkage=.05)
yhat_test8= predict(m8, gb_test, n.trees=5000)
summary(m8)
rmse.boost=rmse(gb_test$Rent,yhat_test8)
table3=as.data.frame(c(info.trees[1],rmse.rf,rmse.boost))
colnames(table3)<-c("RMSE")
row.names(table3) <- c("Tree model","Random Forest",
"Boosting")
table3=kable(table3,digits=2)%>%
kable_styling()
table3
table3=as.data.frame(c(info.trees[1],rmse.rf,rmse.boost))
colnames(table3)<-c("RMSE")
row.names(table3) <- c("Tree model","Random Forest",
"Boosting")
table3=kable(table3,digits=2)%>%
kable_styling()
table3
varImpPlot(m7,type=2,main="")
marm4=margins(m4)
marm4
marm4$green_rating
View(marm4)
View(marm4)
sum(marm4$green_rating)
View(marm4)
View(marm4)
marm4
names(marm4)
marm4$fitted
marm4$Var_dydx_green_rating
marm4$dydx_green_rating)
varImpPlot(m7,type=2,main="")
rmse.lm=as.data.frame(rmse.lm)
colnames(rmse.lm)<-c("RMSE")
row.names(rmse.lm) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
a=cbind(rmse.lm,AIC,BIC,DF)
table1=kable(a, digits=2, padding = 2)%>%
kable_styling()
table1
()
()
rmse.lm=as.data.frame(rmse.lm)
colnames(rmse.lm)<-c("RMSE")
row.names(rmse.lm) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
a=cbind(rmse.lm,AIC,BIC,DF)
table1=kable(a, digits=2, padding = 2)%>%
kable_styling()
table1
tabl1=as.data.frame(rmse.lm)
colnames(table1)<-c("RMSE")
tabl1=as.data.frame(rmse.lm)
colnames(table1)<-c("RMSE")
table1=as.data.frame(rmse.lm)
colnames(table1)<-c("RMSE")
row.names(table1) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
a=cbind(table1,AIC,BIC,DF)
table1=kable(a, digits=2, padding = 2)%>%
kable_styling()
table1
table1=as.data.frame(rmse.lm)
colnames(table1)<-c("RMSE")
row.names(table1) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
tabl1=cbind(table1,AIC,BIC,DF)
table1=kable(table1, digits=2, padding = 2)%>%
kable_styling()
table1
table1=as.data.frame(rmse.lm)
colnames(table1)<-c("RMSE")
row.names(table1) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
a=cbind(table1,AIC,BIC,DF)
table1=kable(table1, digits=2, padding = 2)%>%
kable_styling()
table1
table1=as.data.frame(rmse.lm)
colnames(table1)<-c("RMSE")
row.names(table1) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
a=cbind(table1,AIC,BIC,DF)
table1=kable(table1, digits=2, padding = 2)%>%
kable_styling()
table1
table1=as.data.frame(rmse.lm)
colnames(table1)<-c("RMSE")
row.names(table1) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
a=cbind(table1,AIC,BIC,DF)
table1=kable(a, digits=2, padding = 2)%>%
kable_styling()
table1
info.lasso=as.data.frame(info.lasso)
colnames(info.lasso)<-c("Lasso Model")
row.names(info.lasso) <- c("RMSE","Log Lambda",
"Number of coefficients")
table2=kable(info.lasso,digits=2)%>%
kable_styling(bootstrap_options = "striped", position = "float_right")
table2
info.lasso=as.data.frame(info.lasso)
colnames(info.lasso)<-c("Model 5: Lasso Model")
row.names(info.lasso) <- c("RMSE","Log Lambda",
"Number of coefficients")
table2=kable(info.lasso,digits=2)%>%
kable_styling(bootstrap_options = "striped", position = "float_right")
table2
table3=as.data.frame(c(info.trees[1],rmse.rf,rmse.boost))
colnames(table3)<-c("RMSE")
row.names(table3) <- c("Model 6: Tree model","Model 7:Random Forest",
"Model 8: Boosting")
table3=kable(table3,digits=2)%>%
kable_styling()
table3
table1=as.data.frame(rmse.lm)
#############################################################
#####APPROACH 1 fitting Linear models and step selection ############
#############################################################
#### Null model####
m0 = lm(Rent~1, data=gb)
library(mosaic)
library(tidyverse)
library(Metrics)
library(gamlr)
library(margins)
library(rpart)
library(caret)
library(knitr)
library(kableExtra)
library(randomForest)
library(gbm)
greenbuildings = read.csv("greenbuildings.csv", header=TRUE)
greenbuildings = na.omit(greenbuildings)
gb = greenbuildings[which(greenbuildings$leasing_rate != 0),]
gb$size = gb$size/1000
#############################################################
#####APPROACH 1 fitting Linear models and step selection ############
#############################################################
#### Null model####
m0 = lm(Rent~1, data=gb)
summary(m0)
#### Manual built model####
m1  = lm(Rent ~ . -CS_PropertyID-LEED-Energystar
-Precipitation-cd_total_07-hd_total07, data=gb)
summary(m1)
#### Manual model allowing interactions ####
m2  = lm(Rent ~ (. -CS_PropertyID-LEED-Energystar
-Precipitation-cd_total_07-hd_total07)^2, data=gb)
summary(m2)
#### Step selection ####
m3 = step(m0, scope=formula(m1), dir="forward")
summary(m3)
formula(m3)
m4 = step(m0, scope=formula(m2), dir="forward")
summary(m4)
formula(m4)
marm4=margins(m4)
# Compare out of sample performance
n = nrow(gb)
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
rmse_lm = do(50)*{
# re-split into train and test cases with the same sample sizes
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
gb_train = gb[train_cases,]
gb_test = gb[test_cases,]
# Fit to the training data
# use `update` to refit the same model with a different set of data
lm1 = update(m1, data=gb_train)
lm2 = update(m2, data=gb_train)
lm3 = update(m3, data=gb_train)
lm4 = update(m4, data=gb_train)
# Predictions out of sample
yhat_test1 = predict(lm1, gb_test)
yhat_test2 = predict(lm2, gb_test)
yhat_test3 = predict(lm3, gb_test)
yhat_test4 = predict(lm4, gb_test)
c(rmse(gb_test$Rent, yhat_test1),
rmse(gb_test$Rent, yhat_test2),
rmse(gb_test$Rent, yhat_test3),
rmse(gb_test$Rent, yhat_test4))
}
rmse.lm=colMeans(rmse_lm)
aic.lm=AIC(m1,m2,m3,m4)
bic.lm=BIC(m1,m2,m3,m4)
table1=as.data.frame(rmse.lm)
colnames(table1)<-c("RMSE")
row.names(table1) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
a=cbind(table1,AIC,BIC,DF)
table1=kable(a, digits=2, padding = 2)%>%
kable_styling()
table1
a=as.data.frame(rmse.lm)
colnames(a)<-c("RMSE")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
b=cbind(a,AIC,BIC,DF)
table1=kable(b, digits=2, padding = 2)%>%
kable_styling()
table1
a=as.data.frame(rmse.lm)
colnames(a)<-c("RMSE")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
b=cbind(a,AIC,BIC,DF)
table1=kable(b, digits=2, padding = 2)%>%
kable_styling()
table1
a=as.data.frame(rmse.lm)
colnames(a)<-c("RMSE")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
b=cbind(a,AIC,BIC,DF)
table1=kable(b, digits=2, padding = 2)%>%
kable_styling()
table1
a=as.data.frame(rmse.lm)
colnames(a)<-c("RMSE")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
b=cbind(a,AIC,BIC,DF)
table1=kable(b, digits=2, padding = 2)%>%
kable_styling()
table1
a=as.data.frame(rmse.lm)
colnames(a)<-c("RMSE")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
b=cbind(a,AIC,BIC,DF)
table1=kable(b, digits=2, padding = 2)%>%
kable_styling()
table1
()
marm4
a=as.data.frame(rmse.lm)
colnames(a)<-c("RMSE")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
b=cbind(a,AIC,BIC,DF)
table1=kable(b, digits=2, padding = 2)%>%
kable_styling()
table1
rmse.lm=colMeans(rmse_lm)
a=as.data.frame(rmse.lm)
View(a)
a=rmse.lm
cbind(a,AIC,BIC,DF)
a=cbind(rmse.lm,AIC,BIC,DF)
View(a)
colnames(a)<-c("RMSE","AIC","BIC","DF")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
View(a)
a=cbind(rmse.lm,AIC,BIC,DF)
colnames(a)<-c("RMSE","AIC","BIC","DF")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
table1=kable(a, digits=2, padding = 2)%>%
kable_styling()
table1
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
a=cbind(rmse.lm,AIC,BIC,DF)
colnames(a)<-c("RMSE","AIC","BIC","DF")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
table1=kable(a, digits=2, padding = 2)%>%
kable_styling()
table1
info.lasso=as.data.frame(info.lasso)
setwd(C:/Users/clark/OneDrive/UTEXAS/Spring20/Data Mining/DM-SL/DM-SL/Assignment3)
setwd("/Users/clark/OneDrive/UTEXAS/Spring20/Data Mining/DM-SL/DM-SL/Assignment3")
library(mosaic)
library(tidyverse)
library(Metrics)
library(gamlr)
library(margins)
library(rpart)
library(caret)
library(knitr)
library(kableExtra)
library(randomForest)
library(gbm)
greenbuildings = read.csv("greenbuildings.csv", header=TRUE)
greenbuildings = na.omit(greenbuildings)
gb = greenbuildings[which(greenbuildings$leasing_rate != 0),]
gb$size = gb$size/1000
library(mosaic)
library(tidyverse)
library(Metrics)
library(gamlr)
library(margins)
library(rpart)
library(caret)
library(knitr)
library(kableExtra)
library(randomForest)
library(gbm)
greenbuildings = read.csv("greenbuildings.csv", header=TRUE)
greenbuildings = na.omit(greenbuildings)
gb = greenbuildings[which(greenbuildings$leasing_rate != 0),]
gb$size = gb$size/1000
#############################################################
#####APPROACH 1 fitting Linear models and step selection ############
#############################################################
#### Null model####
m0 = lm(Rent~1, data=gb)
summary(m0)
#### Manual built model####
m1  = lm(Rent ~ . -CS_PropertyID-LEED-Energystar
-Precipitation-cd_total_07-hd_total07, data=gb)
summary(m1)
#### Manual model allowing interactions ####
m2  = lm(Rent ~ (. -CS_PropertyID-LEED-Energystar
-Precipitation-cd_total_07-hd_total07)^2, data=gb)
summary(m2)
#### Step selection ####
m3 = step(m0, scope=formula(m1), dir="forward")
summary(m3)
formula(m3)
m4 = step(m0, scope=formula(m2), dir="forward")
summary(m4)
formula(m4)
marm4=margins(m4)
# Compare out of sample performance
n = nrow(gb)
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train
rmse_lm = do(50)*{
# re-split into train and test cases with the same sample sizes
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
gb_train = gb[train_cases,]
gb_test = gb[test_cases,]
# Fit to the training data
# use `update` to refit the same model with a different set of data
lm1 = update(m1, data=gb_train)
lm2 = update(m2, data=gb_train)
lm3 = update(m3, data=gb_train)
lm4 = update(m4, data=gb_train)
# Predictions out of sample
yhat_test1 = predict(lm1, gb_test)
yhat_test2 = predict(lm2, gb_test)
yhat_test3 = predict(lm3, gb_test)
yhat_test4 = predict(lm4, gb_test)
c(rmse(gb_test$Rent, yhat_test1),
rmse(gb_test$Rent, yhat_test2),
rmse(gb_test$Rent, yhat_test3),
rmse(gb_test$Rent, yhat_test4))
}
rmse.lm=colMeans(rmse_lm)
aic.lm=AIC(m1,m2,m3,m4)
bic.lm=BIC(m1,m2,m3,m4)
AIC=aic.lm$AIC
BIC=bic.lm$BIC
DF=bic.lm$df
a=cbind(rmse.lm,AIC,BIC,DF)
colnames(a)<-c("RMSE","AIC","BIC","DF")
row.names(a) <- c("Model 1: Manual built","Model 2: Interactions
","Model 3: Manual built + step","Model 4: Interactions + step")
table1=kable(a, digits=2, padding = 2)
table1
info.lasso
rmse_lasso = do(10)*{
# re-split into train and test cases with the same sample sizes
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
gb_train = gb[train_cases,]
gb_test = gb[test_cases,]
x_train= sparse.model.matrix(Rent ~ (.-CS_PropertyID-LEED-Energystar)^2, data=gb_train)[,-1] # do -1 to drop intercept!
x_test= sparse.model.matrix(Rent ~ (.-CS_PropertyID-LEED-Energystar)^2, data=gb_test)[,-1]
y=gb_train$Rent
###### CV Lasso best model ######
cvm5= cv.gamlr(x_train, y, nfold=10,  verb=TRUE)
# plot the out-of-sample deviance as a function of log lambda
# Q: what are the bars associated with each dot?
plasso=plot(cvm5, bty="n")
## CV min deviance selection
scb.min = coef(cvm5, select="min")
lambda=log(cvm5$lambda.min)
coef.lasso=sum(scb.min!=0)
yhat_test5 = as.numeric(predict(cvm5, x_test, select="min"))
c(rmse(gb_test$Rent,yhat_test5),lambda,coef.lasso)
}
info.lasso=colMeans(rmse_lasso)
info.lasso
lambda=info.lasso[2]
lambda1=info.lasso[2]
lambda1
info.lasso[3]
coef.lasso1
coef.lasso1=info.lasso[3]
